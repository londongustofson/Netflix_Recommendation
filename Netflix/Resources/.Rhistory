dims = c(length(unique(x1$userId)),
length(unique(x1$movieId))),
dimnames = list(paste("u", 1:length(unique(x1$userId)), sep = ""),
paste("m", 1:length(unique(x1$movieId)), sep = "")))
sparse_ratings[1:10,1:10]
#Convert rating matrix into a recommenderlab sparse matrix
ratingMat <- new("realRatingMatrix", data = sparse_ratings)
ratingMat
#To measure the similarity between user, can use:
#+ Minkowski Distance
#+ Mahalanobis distance
#+ Pearson correlation
#+ Cosine similarity --> the chosen one
#ADVANTAGES:
#Solves the problem of sparsity, scalability and cold start and it is more robust to noise.
#It improves prediction accuracy and consistency
#The Cosine similarity can still be calculated even though the matrix has many missing elements.
#As the dimensional space becomes large, this still works well.
#The low Computational complexity , especially for sparse vectors.
#i calculate the user similarity using the cosine similarity
similarity_users <- similarity(ratingMat[1:50,],
method = "cosine",
which = "users")
image(as.matrix(similarity_users), main = "User similarity")
#Using the same approach, I compute similarity between  movies.
similarity_movies <- similarity(ratingMat[,1:50],
method = "cosine",
which = "items")
image(as.matrix(similarity_movies), main = "Movies similarity")
#to face the RAM memory we'll use Irlba package, which it is a fast and memory-efficient way to compute a partial SVD
set.seed(1)
Y <- irlba(sparse_ratings,tol=1e-4,verbose=TRUE,nv = 100, maxit = 1000)
The analysis of the previous similarity matrices leads to the
#thought that it can exists users with similar ratings patterns and
#movies with similar rating patterns. However Sparsity and the curse of
#dimensionality remain a recurent problem, and we have to deal with many
#NA too. Dimensionality reduction techniques such as "pca" and "svd" can help overcome these problem by transforming the original high-dimensional space into a lower-dimensionality.
# plot singular values
plot(Y$d, pch=20, col = "blue", cex = 1.5, xlab='Singular Value', ylab='Magnitude',
main = "Singular Values for User-Movie Matrix")
# calculate sum of squares of all singular values
all_sing_sq <- sum(Y$d^2)
# variability described by first 6, 12, and 20 singular values
first_six <- sum(Y$d[1:6]^2)
print(first_six/all_sing_sq)
first_12 <- sum(Y$d[1:12]^2)
print(first_12/all_sing_sq)
first_20 <- sum(Y$d[1:20]^2)
print(first_20/all_sing_sq)
perc_vec <- NULL
for (i in 1:length(Y$d)) {
perc_vec[i] <- sum(Y$d[1:i]^2) / all_sing_sq
}
plot(perc_vec, pch=20, col = "blue", cex = 1.5, xlab='Singular Value', ylab='% of Sum of Squares of Singular Values', main = "Choosing k for Dimensionality Reduction")
lines(x = c(0,100), y = c(.90, .90))
#First six singular values explain more than half of the variability of the imputed ratings matrix, with the first dozen explaining nearly 70% and the first twenty explaining more than 75%
#To find the exact value of k, i calculate  the length of the vector that remains from our running sum of squares after excluding any items within that vector that exceed 0.90.
k = length(perc_vec[perc_vec <= .90])
k
#I get the decomposition of Y ; 3 matrices U, D, and V accordingly:
U_k <- Y$u[, 1:k]
dim(U_k)
D_k <- Diagonal(x = Y$d[1:k])
dim(D_k)
V_k <- t(Y$v)[1:k, ]
dim(V_k)
#  Determine the minimum number of movies per user.
#Determine the minimum number of users per movie.
#Select the users and movies matching these criteria.
#a.
min_n_movies <- quantile(rowCounts(ratingMat), 0.9)
print(min_n_movies)
#b.
min_n_users <- quantile(colCounts(ratingMat), 0.9)
print(min_n_users)
#c.
ratings_movies <- ratingMat[rowCounts(ratingMat) > min_n_movies,
colCounts(ratingMat) > min_n_users]
ratings_movies
#####MACHING LEARNING PART
#i define the RMSE function as:
RMSE <- function(true_ratings, predicted_ratings){
sqrt(mean((true_ratings - predicted_ratings)^2))
}
# Split the data into training and test set
sample_size = floor(0.9*nrow(x1))
set.seed(777)
# randomly split data in r
picked = sample(seq_len(nrow(x1)),size = sample_size)
Training_set =x1[picked,];
validation =x1[-picked,];
# i calculate the average of all ratings of the x1 set
mu <- mean(x1$rating)
# i calculate b_i on the training set
movie_avgs <- x1 %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
# predicted ratings
predicted_ratings_bi <- mu + validation %>%
left_join(movie_avgs, by='movieId') %>%
.$b_i
#b.movie + user effect
#i calculate b_u using the training set
user_avgs <- x1 %>%
left_join(movie_avgs, by='movieId') %>%
group_by(userId) %>%
summarize(b_u = mean(rating - mu - b_i))
#predicted ratings
predicted_ratings_bu <- validation %>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
mutate(pred = mu + b_i + b_u) %>%
.$pred
#c.movie + user + time effect
#i create a copy of validation set , valid, and create the date feature which is the timestamp converted to a datetime object  and  rounded by week.
valid <- validation
valid <- valid %>%
mutate(date = round_date(as_datetime(timestamp), unit = "week"))
# i calculate time effects ( b_t) using the training set
temp_avgs <- x1 %>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
group_by(date) %>%
summarize(b_t = mean(rating - mu - b_i - b_u))
# predicted ratings
predicted_ratings_bt <- valid %>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
left_join(temp_avgs, by='date') %>%
mutate(pred = mu + b_i + b_u + b_t) %>%
.$pred
# predicted ratings
predicted_ratings_bt <- valid %>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
left_join(temp_avgs, by='date') %>%
mutate(pred = mu + b_i + b_u + b_t) %>%
.$pred
#d.  i calculate the RMSE for movies, users and time effects
rmse_model1 <- RMSE(validation$rating,predicted_ratings_bi)
rmse_model1
rmse_model2 <- RMSE(validation$rating,predicted_ratings_bu)
rmse_model2
rmse_model3 <- RMSE(valid$rating,predicted_ratings_bt)
rmse_model3
#before to proceed with regularization, i just remove the object copy of validation, "valid"
rm(valid)
# remembering (5), $\lambda$ is a tuning parameter. We can use cross-validation to choose it
lambdas <- seq(0, 10, 0.25)
rmses <- sapply(lambdas, function(l){
mu_reg <- mean(x1$rating)
b_i_reg <- x1 %>%
group_by(movieId) %>%
summarize(b_i_reg = sum(rating - mu_reg)/(n()+l))
b_u_reg <- x1 %>%
left_join(b_i_reg, by="movieId") %>%
group_by(userId) %>%
summarize(b_u_reg = sum(rating - b_i_reg - mu_reg)/(n()+l))
predicted_ratings_b_i_u <-
validation %>%
left_join(b_i_reg, by = "movieId") %>%
left_join(b_u_reg, by = "userId") %>%
mutate(pred = mu_reg + b_i_reg + b_u_reg) %>%
.$pred
return(RMSE(validation$rating,predicted_ratings_b_i_u))
})
qplot(lambdas, rmses)
#For the full model, the optimal  ?? is:
lambda <- lambdas[which.min(rmses)]
lambda
rmse_model4 <- min(rmses)
rmse_model4
install.packages("kableExtra")
library("kableExtra")
#summarize all the rmse on validation set for Linear regression models
rmse_results <- data.frame(methods=c("movie effect","movie + user effects","movie + user + time effects", "Regularized Movie + User Effect Model"),rmse = c(rmse_model1, rmse_model2,rmse_model3, rmse_model4))
kable(rmse_results) %>%
kable_styling(bootstrap_options = "striped" , full_width = F , position = "center") %>%
kable_styling(bootstrap_options = "bordered", full_width = F , position ="center") %>%
column_spec(1,bold = T ) %>%
column_spec(2,bold =T ,color = "white" , background ="#D7261E")
#######################
#1.2 recommender engines
# a. POPULAR , UBCF and IBCF algorithms of the recommenderlab package
model_pop <- Recommender(ratings_movies, method = "POPULAR",
param=list(normalize = "center"))
#prediction example on the first 10 users
pred_pop <- predict(model_pop, ratings_movies[1:10], type="ratings")
as(pred_pop, "matrix")[,1:10]
#Calculation of rmse for popular method
set.seed(1)
e <- evaluationScheme(ratings_movies, method="split", train=0.7, given=-5)
?evaluationScheme
#5 ratings of 30% of users are excluded for testing
model_pop <- Recommender(getData(e, "train"), "POPULAR")
prediction_pop <- predict(model_pop, getData(e, "known"), type="ratings")
rmse_popular <- calcPredictionAccuracy(prediction_pop, getData(e, "unknown"))[1]
rmse_popular
Movies_Whiskers$movieId <- as.numeric(Movies_Whiskers$movieId)
movielens <- left_join(Ratings_Whiskers, Movies_Whiskers, by = "movieId")
# Validation set will be 10% of MovieLens data
set.seed(99)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]
# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>%
semi_join(edx, by = "movieId") %>%
semi_join(edx, by = "userId")
# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)
rm(dl, Ratings_Whiskers, Movies_Whiskers, test_index, temp, movielens, removed)
# generate reproducible partition
set.seed(99)
# test set will be 10% of edx data
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
train <- edx[-test_index,]
temp <- edx[test_index,]
# Make sure userId and movieId in test set are also in train set
test <- temp %>%
semi_join(train, by = "movieId") %>%
semi_join(train, by = "userId")
# Add rows removed from test set back into train set
removed <- anti_join(temp, test)
train <- rbind(train, removed)
rm(removed, temp, test_index)
# show train set
train %>% as_tibble()
train %>% summarize(
n_users=n_distinct(userId),# unique users from train
n_movies=n_distinct(movieId),# unique movies from train
min_rating=min(rating),  # the lowest rating
max_rating=max(rating) # the highest rating
)
# matrix for 5 movies and 7 users
keep <- train %>%
count(movieId) %>%
top_n(5, n) %>%
.$movieId
tab <- train %>%
filter(movieId%in%keep) %>%
filter(userId %in% c(13:20)) %>%
select(userId, title, rating) %>%
mutate(title = str_remove(title, ", The"),
title = str_remove(title, ":.*")) %>%
spread(title, rating)
tab %>% knitr::kable()
# matrix for a random sample of 100 movies and 100 users with yellow
# indicating a user/movie combination for which we have a rating.
users <- sample(unique(train$userId), 100)
rafalib::mypar()
train %>% filter(userId %in% users) %>%
select(userId, movieId, rating) %>%
mutate(rating = 1) %>%
spread(movieId, rating) %>% select(sample(ncol(.), 100)) %>%
as.matrix() %>% t(.) %>%
image(1:100, 1:100,. , xlab="Movies", ylab="Users")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")
# plot count rating by movie
train %>%
count(movieId) %>%
ggplot(aes(n)) +
geom_histogram(bins = 30, color = "blue") +
scale_x_log10() +
ggtitle("Movies")
# plot count rating by user
train %>%
count(userId) %>%
ggplot(aes(n)) +
geom_histogram(bins = 30, color = "orange") +
scale_x_log10() +
ggtitle("Users")
# to save space
rm(tab, keep, users)
mu <- mean(train$rating) # compute mean rating
mu
naive_rmse <- RMSE(test$rating, mu) # compute root mean standard error
naive_rmse
# create a results table with this approach
rmse_results <- tibble(method = "Just the average", RMSE = naive_rmse)
rmse_results %>% knitr::kable()
mu <- mean(train$rating)
movie_avgs <- train %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"))
# create a results table with this and prior approaches
predicted_ratings <- mu + test %>%
left_join(movie_avgs, by='movieId') %>%
.$b_i
# create a results table with this and prior approach
model_1_rmse <- RMSE(predicted_ratings, test$rating)
rmse_results <- bind_rows(rmse_results,
tibble(method="Movie Effect Model on test set",
RMSE = model_1_rmse ))
rmse_results %>% knitr::kable()
train %>%
group_by(userId) %>%
summarize(b_u = mean(rating - mu)) %>%
ggplot(aes(b_u)) +
geom_histogram(bins = 30, color = "blue")
# compute user effect b_u
user_avgs <- train %>%
left_join(movie_avgs, by='movieId') %>%
group_by(userId) %>%
summarize(b_u = mean(rating - mu - b_i))
# compute predicted values on test set
predicted_ratings <- test %>%
left_join(movie_avgs, by='movieId') %>%
left_join(user_avgs, by='userId') %>%
mutate(pred = mu + b_i + b_u) %>%
.$pred
# create a results table with this and prior approaches
model_2_rmse <- RMSE(predicted_ratings, test$rating)
rmse_results <- bind_rows(rmse_results,
tibble(method="Movie and User Effects Model on test set",
RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()
# Regularization
# connect movieId to movie title
movie_titles <- train %>%
select(movieId, title) %>%
distinct()
# top 10 best movies based on b_i
movie_avgs %>% left_join(movie_titles, by="movieId") %>%
arrange(desc(b_i)) %>%
select(title, b_i) %>%
slice(1:10) %>%
knitr::kable()
# top 10 worse movies based on b_i
movie_avgs %>% left_join(movie_titles, by="movieId") %>%
arrange(b_i) %>%
select(title, b_i) %>%
slice(1:10) %>%
knitr::kable()
# add number of rating of the "best" obscure movies
train %>% count(movieId) %>%
left_join(movie_avgs) %>%
left_join(movie_titles, by="movieId") %>%
arrange(desc(b_i)) %>%
select(title, b_i, n) %>%
slice(1:10) %>%
knitr::kable()
# add number of rating of the "worse" obscure movies
train %>% count(movieId) %>%
left_join(movie_avgs) %>%
left_join(movie_titles, by="movieId") %>%
arrange(b_i) %>%
select(title, b_i, n) %>%
slice(1:10) %>%
knitr::kable()
# use cross-validation to pick a lambda:
lambda <- seq(0, 10, 0.25)
rmses <- sapply(lambda, function(l){
mu <- mean(train$rating)
b_i <- train %>%
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+l))
b_u <- train %>%
left_join(b_i, by="movieId") %>%
group_by(userId) %>%
summarize(b_u = sum(rating - b_i - mu)/(n()+l))
predicted_ratings <-
train %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(pred = mu + b_i + b_u) %>%
.$pred
return(RMSE(train$rating, predicted_ratings))
})
qplot(lambda, rmses)
# pick lambda with minimun rmse
lambda <- lambda[which.min(rmses)]
# print lambda
lambda
# compute movie effect with regularization on train set
b_i <- train %>%
group_by(movieId) %>%
summarize(b_i = sum(rating - mu)/(n()+lambda))
# compute user effect with regularization on train set
b_u <- train %>%
left_join(b_i, by="movieId") %>%
group_by(userId) %>%
summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))
# # compute predicted values on test set
predicted_ratings <-
test %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(pred = mu + b_i + b_u) %>%
pull(pred)
# create a results table with this and prior approaches
model_3_rmse <- RMSE(test$rating, predicted_ratings)
rmse_results <- bind_rows(rmse_results,
tibble(method="Reg Movie and User Effect Model on test set",
RMSE = model_3_rmse))
rmse_results %>% knitr::kable()
# compute movie effect without regularization on train set
b_i <- train %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
# compute user effect without regularization on train set
b_u <- train %>%
left_join(b_i, by="movieId") %>%
group_by(userId) %>%
summarize(b_u = mean(rating - b_i - mu))
# compute residuals on train set
train <- train %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(res = rating - mu - b_i - b_u)
# compute residuals on test set
test <- test %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(res = rating - mu - b_i - b_u)
# create data saved on disk in 3 columns with no headers
train_data <- data_memory(user_index = train$userId, item_index = train$movieId,
rating = train$res, index1 = T)
test_data <- data_memory(user_index = test$userId, item_index = test$movieId, index1 = T)
# create a model object
recommender <- Reco()
# This is a randomized algorithm
set.seed(77)
# call the `$tune()` method to select best tuning parameters
res = recommender$tune(
train_data,
opts = list(dim = c(10, 20, 30),
costp_l1 = 0, costq_l1 = 0,
lrate = c(0.05, 0.1, 0.2), nthread = 2)
)
# show best tuning parameters
print(res$min)
# Train the model by calling the `$train()` method
# some parameters coming from the result of `$tune()`
# This is a randomized algorithm
set.seed(77)
suppressWarnings(recommender$train(train_data, opts = c(dim = 30, costp_l1 = 0,
costp_l2 = 0.01, costq_l1 = 0,
costq_l2 = 0.1, lrate = 0.05,
verbose = FALSE)))
# use the `$predict()` method to compute predicted values
# return predicted values in memory
predicted_ratings <- recommender$predict(test_data, out_memory()) + mu + test$b_i + test$b_u
# ceiling rating at 5
ind <- which(predicted_ratings > 5)
predicted_ratings[ind] <- 5
# floor rating at 0.50
ind <- which(predicted_ratings < 0.5)
predicted_ratings[ind] <- 0.5
# create a results table with this approach
model_4_rmse <- RMSE(test$rating, predicted_ratings)
rmse_results <- bind_rows(rmse_results,
tibble(method="Movie and User + Matrix Fact. on test set",
RMSE = model_4_rmse))
rmse_results %>% knitr::kable()
# compute movies effect without regularization on edx set
b_i <- edx %>%
group_by(movieId) %>%
summarize(b_i = mean(rating - mu))
# compute users effect without regularization on edx set
b_u <- edx %>%
left_join(b_i, by="movieId") %>%
group_by(userId) %>%
summarize(b_u = mean(rating - b_i - mu))
# compute residuals on edx set
edx <- edx %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(res = rating - mu - b_i - b_u)
# compute residuals on validation set
validation <- validation %>%
left_join(b_i, by = "movieId") %>%
left_join(b_u, by = "userId") %>%
mutate(res = rating - mu - b_i - b_u)
# Using recosystem
# create data saved on disk in 3 columns with no headers
edx_data <- data_memory(user_index = edx$userId, item_index = edx$movieId,
rating = edx$res, index1 = T)
validation_data <- data_memory(user_index = validation$userId, item_index = validation$movieId, index1 = T)
# create a model object
recommender <- Reco()
# Train the model by calling the `$train()` method
# some parameters coming from the result of `$tune()`
# This is a randomized algorithm
set.seed(77)
suppressWarnings(recommender$train(edx_data, opts = c(dim = 30, costp_l1 = 0,
costp_l2 = 0.01, costq_l1 = 0,
costq_l2 = 0.1, lrate = 0.05,
verbose = FALSE)))
# use the `$predict()` method to compute predicted values
# return predicted values in memory
predicted_ratings <- recommender$predict(validation_data, out_memory()) + mu +
validation$b_i + validation$b_u
# ceiling rating at 5
ind <- which(predicted_ratings > 5)
predicted_ratings[ind] <- 5
# floor rating at 5
ind <- which(predicted_ratings < 0.5)
predicted_ratings[ind] <- 0.5
# create a results table with this and prior approaches
model_5_rmse <- RMSE(validation$rating, predicted_ratings)
rmse_results <- bind_rows(rmse_results,
tibble(method="Movie and User effects and Matrix Fact. on validation set",
RMSE = model_5_rmse))
rmse_results %>% knitr::kable()
install.packages("kableExtra")
movies_Whiskers$movieid <- as.numeric(movies_Whiskers$movieid)
setwd("~/Desktop/TBS/projects/Netflix/Resources")
movies_Whiskers$movieid <- as.numeric(movies_Whiskers$movieid)
